{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале напишем простую функцию для записи ответов в текстовый файл. Ответами будут числа, полученные в ходе решения этого задания, округленные до 3 знаков после запятой. Полученные файлы после выполнения задания надо отправить в форму на странице задания на Coursera.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, filename):\n",
    "    with open(filename, 'w') as f_out:\n",
    "        f_out.write(str(round(answer, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('course_2_week_1_advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Дисперсия</th>\n",
       "      <th>Матожидание</th>\n",
       "      <th>Медиана</th>\n",
       "      <th>Стандартное отклонение</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TV</th>\n",
       "      <td>7370.949893</td>\n",
       "      <td>147.0425</td>\n",
       "      <td>149.75</td>\n",
       "      <td>85.854236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radio</th>\n",
       "      <td>220.427743</td>\n",
       "      <td>23.2640</td>\n",
       "      <td>22.90</td>\n",
       "      <td>14.846809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Newspaper</th>\n",
       "      <td>474.308326</td>\n",
       "      <td>30.5540</td>\n",
       "      <td>25.75</td>\n",
       "      <td>21.778621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sales</th>\n",
       "      <td>27.221853</td>\n",
       "      <td>14.0225</td>\n",
       "      <td>12.90</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Дисперсия  Матожидание  Медиана  Стандартное отклонение\n",
       "TV         7370.949893     147.0425   149.75               85.854236\n",
       "Radio       220.427743      23.2640    22.90               14.846809\n",
       "Newspaper   474.308326      30.5540    25.75               21.778621\n",
       "Sales        27.221853      14.0225    12.90                5.217457"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats = pd.DataFrame({ \n",
    "        'Дисперсия' : adver_data.var(),\n",
    "        'Стандартное отклонение' : adver_data.std(),\n",
    "        'Матожидание' : adver_data.mean(),\n",
    "        'Медиана' : adver_data.median()\n",
    "    })\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X=adver_data[['TV','Radio','Newspaper']].values\n",
    "y=adver_data[['Sales']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "means, stds = np.mean(X, axis=0), np.std(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = (X-means)/stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.hstack ((np.ones(X.shape[0]).reshape((X.shape[0],1)),X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    dif=y-y_pred\n",
    "    dif_sq=dif**2\n",
    "    dif_sum=dif_sq.sum()\n",
    "    return dif_sum/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Запишите ответ в файл '1.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.34575\n"
     ]
    }
   ],
   "source": [
    "answer1 = mserror(y,np.median(y))\n",
    "print(answer1)\n",
    "write_answer_to_file(answer1, '1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w={(X^TX)}^{-1}X^Ty$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    X1=np.transpose(X)\n",
    "    X2=np.dot(X1,X)\n",
    "    X3=np.linalg.inv(X2)\n",
    "    X4=np.dot(X3,X1)\n",
    "    w=np.dot(X4,y)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14.0225    ]\n",
      " [  3.91925365]\n",
      " [  2.79206274]\n",
      " [ -0.02253861]]\n"
     ]
    }
   ],
   "source": [
    "norm_eq_weights = normal_equation(X, y)\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Запишите ответ в файл '2.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0225\n"
     ]
    }
   ],
   "source": [
    "answer2 = np.dot([1,0,0,0],norm_eq_weights)[0]\n",
    "print(answer2)\n",
    "write_answer_to_file(answer2, '2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    return np.dot(X,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения? Запишите ответ в файл '3.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78412631451\n"
     ]
    }
   ],
   "source": [
    "y_pred=linear_prediction(X,norm_eq_weights)\n",
    "answer3 = mserror(y,y_pred)\n",
    "print(answer3)\n",
    "write_answer_to_file(answer3, '3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.88066244]\n",
      "-5.88066244265\n",
      "[[  8.84018288  12.54044836  13.00111167  13.6792083 ]\n",
      " [  8.84039274  12.54065822  13.00132153  13.67941816]\n",
      " [  8.83946849  12.53973397  13.00039728  13.67849391]\n",
      " [  8.8396453   12.53991078  13.00057409  13.67867072]]\n"
     ]
    }
   ],
   "source": [
    "train_ind=102\n",
    "#w=np.zeros(4)\n",
    "w= np.array([  8.83980467,12.54007015,13.00073346,13.67883009])\n",
    "\n",
    "#X[train_ind,:]\n",
    "#(X[train_ind,1])*w.dot(X[train_ind,:])-y[train_ind]\n",
    "print (X[train_ind,1]*(X[train_ind,:].dot(w)-y[train_ind]))\n",
    "print ((X[train_ind,1])*(np.dot(X[train_ind,:],w)-y[train_ind])[0])\n",
    "#grad0 = (2/len(y)) * (w.dot(X[train_ind,:])-y[train_ind])\n",
    "\n",
    "\n",
    "eta=0.01\n",
    "grad0 = (2/len(y)) * (w.dot(X[train_ind,:])-y[train_ind])\n",
    "grad1 = (2/len(y)) * X[train_ind,1]*(X[train_ind,:].dot(w)-y[train_ind])\n",
    "grad2 = (2/len(y)) * X[train_ind,2]*(X[train_ind,:].dot(w)-y[train_ind])\n",
    "grad3 = (2/len(y)) * X[train_ind,3]*(X[train_ind,:].dot(w)-y[train_ind])\n",
    "print ( w - eta * np.array([grad0, grad1, grad2, grad3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.84018288  12.54044836  13.00111167  13.6792083 ]\n",
      " [  8.84039274  12.54065822  13.00132153  13.67941816]\n",
      " [  8.83946849  12.53973397  13.00039728  13.67849391]\n",
      " [  8.8396453   12.53991078  13.00057409  13.67867072]]\n"
     ]
    }
   ],
   "source": [
    "lp=(linear_prediction(X[train_ind,:],w)-y[train_ind])[0]\n",
    "grad0 = lp\n",
    "l=len(y)\n",
    "grad1 = (X[train_ind,1])*lp\n",
    "grad2 = (X[train_ind,2])*lp\n",
    "grad3 = (X[train_ind,3])*lp\n",
    "grad=np.array([grad0, grad1, grad2, grad3]).reshape(4,1)\n",
    "print (w - (2*eta/l) * grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    l=len(y)\n",
    "    lp=(linear_prediction(X[train_ind,:],w)-y[train_ind])[0]\n",
    "    grad0 = lp\n",
    "    grad1 = (X[train_ind,1])*lp\n",
    "    grad2 = (X[train_ind,2])*lp\n",
    "    grad3 = (X[train_ind,3])*lp\n",
    "    grad=np.array([grad0, grad1, grad2, grad3]).reshape(4,1)\n",
    "    return  w - (2*eta/l) * grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - минимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=0.01, max_iter=10000,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        # Ваш код здесь\n",
    "        iter_num=iter_num+1\n",
    "        w=stochastic_gradient_step(X,y,w,random_ind,eta)\n",
    "        y_pred=linear_prediction(X,w)\n",
    "        errors.append(mserror(y,y_pred))\n",
    "        if verbose:\n",
    "            print (iter_num)\n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.842743    8.842743    8.842743    8.842743  ]\n",
      " [ 2.48883009  2.48883009  2.48883009  2.48883009]\n",
      " [ 1.71429214  1.71429214  1.71429214  1.71429214]\n",
      " [ 0.43255158  0.43255158  0.43255158  0.43255158]]\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X,y,np.zeros(4))\n",
    "print (stoch_grad_desc_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x295f638add8>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIEREpEwKCBERKZMCQkREyqSAEBGRMv1/Mu7ngkAMAM8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x295f638d860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(50), stoch_errors_by_iter[:50])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x295f626c1d0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x295f6266518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.842743  ],\n",
       "       [ 2.48883009],\n",
       "       [ 1.71429214],\n",
       "       [ 0.43255158]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_grad_desc_weights\n",
    "array([[ 8.842743  ],\n",
    "       [ 2.48883009],\n",
    "       [ 1.71429214],\n",
    "       [ 0.43255158]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131.10677859305656"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(stoch_errors_by_iter)\n",
    "stoch_errors_by_iter[9999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Запишите ответ в файл '4.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.0345299991\n"
     ]
    }
   ],
   "source": [
    "y_pred_grad=linear_prediction(X,stoch_grad_desc_weights)\n",
    "answer4 = mserror(y,y_pred_grad)\n",
    "print(answer4)\n",
    "write_answer_to_file(answer4, '4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответами к заданию будут текстовые файлы, полученные в ходе этого решения. Обратите внимание, что отправленные файлы не должны содержать пустую строку в конце. Данный нюанс является ограничением платформы Coursera. Мы работаем над исправлением этого ограничения.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
